{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.wente\\AppData\\Local\\Temp\\ipykernel_23820\\3391109823.py:3: DtypeWarning: Columns (27,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('df.csv')\n"
     ]
    }
   ],
   "source": [
    "# import df.csv\n",
    "\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your dataframe is df and your date column is 'date'\n",
    "\n",
    "# Convert date to datetime if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by date\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Remove rows where the 'Injury' column has NA values\n",
    "df = df.dropna(subset=['Injury'])\n",
    "\n",
    "# Get unique dates\n",
    "unique_dates = df['Date'].unique()\n",
    "\n",
    "# Decide how many dates to include in each set\n",
    "train_dates = int(len(unique_dates) * 0.8)\n",
    "\n",
    "# Find the index of the last training date\n",
    "last_train_idx = df[df['Date'] == unique_dates[train_dates]].index[-1]\n",
    "\n",
    "# Now you can create your train and test sets\n",
    "train = df.iloc[:last_train_idx + 1]\n",
    "test = df.iloc[last_train_idx + 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns excluding the date column\n",
    "cat_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "# Fit the OneHotEncoder on the training data and transform both train and test data\n",
    "ohe.fit(train[cat_cols])\n",
    "one_hot_encoded_train = ohe.transform(train[cat_cols])\n",
    "one_hot_encoded_test = ohe.transform(test[cat_cols])\n",
    "\n",
    "# Extract numeric data\n",
    "numeric_data_train = train.drop(cat_cols + ['Date', 'Injury'], axis=1).values\n",
    "numeric_data_test = test.drop(cat_cols + ['Date', 'Injury'], axis=1).values\n",
    "\n",
    "\n",
    "# Combine sparse and dense data\n",
    "final_data_train = sp.hstack((one_hot_encoded_train, numeric_data_train)).tocsr()\n",
    "final_data_test = sp.hstack((one_hot_encoded_test, numeric_data_test)).tocsr()\n",
    "\n",
    "\n",
    "\n",
    "# Set up for cross-validation\n",
    "X = final_data_train\n",
    "y = train[\"Injury\"].values  # replace \"Injury\" with your target column name\n",
    "\n",
    "X_test = final_data_test\n",
    "y_test = test[\"Injury\"].values\n",
    "\n",
    "# Initialize a TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = X.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "\n",
    "    mse_scores = []\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
    "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params_\n",
    "\n",
    "final_model = xgb.XGBRegressor(objective='reg:squarederror', **best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "predictions = final_model.predict(final_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-23 15:59:00,011] A new study created in RDB with name: no-name-286bbea7-b86c-450d-af18-d85fcadd081f\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
    "        'objective': 'reg:squarederror',\n",
    "        #'tree_method': 'gpu_hist',  # use GPU-based algorithm\n",
    "        #'gpu_id': 1  # ID of the GPU to use\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 50, 500)\n",
    "    early_stopping_rounds = 50  # Stop if performance hasn't improved for 50 rounds\n",
    "\n",
    "    mse_scores = []\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
    "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "\n",
    "        # Convert to DMatrix\n",
    "        dtrain = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "        dval = xgb.DMatrix(X_val_cv, label=y_val_cv)\n",
    "\n",
    "        # Train the model\n",
    "        model = xgb.train(\n",
    "            params, \n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        # Predict the validation set\n",
    "        y_pred = model.predict(dval)\n",
    "\n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Create a study that uses SQLite storage\n",
    "study = optuna.create_study(direction='minimize', storage='sqlite:///example.db')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimize the study\n",
    "study.optimize(objective, n_trials=100, catch=(Exception,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Define a callback function to record the evaluation results\n",
    "def record_evaluation(results):\n",
    "    def callback(env):\n",
    "        iteration = len(results[\"Train\"][\"mse\"])\n",
    "        results[\"Train\"][\"mse\"].append(env.evaluation_result_list[0][1])\n",
    "        results[\"Test\"][\"mse\"].append(env.evaluation_result_list[1][1])\n",
    "    return callback\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {\n",
    "    \"Train\": {\"mse\": []},\n",
    "    \"Test\": {\"mse\": []},\n",
    "}\n",
    "\n",
    "\n",
    "early_stopping_rounds = 50  # Or any value you prefer\n",
    "\n",
    "# Prepare the DMatrix format for the entire training data and test data\n",
    "dtrain_full = xgb.DMatrix(X, label=y)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)  # Ensure X_test and y_test are prepared\n",
    "\n",
    "# Train the model with the best parameters on the training data\n",
    "final_model = xgb.train(\n",
    "    best_params, \n",
    "    dtrain_full, \n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    evals=[(dtrain_full, 'train'), (dtest, 'test')],\n",
    "    verbose_eval=True,  # If you want to see the training progress\n",
    "    callbacks=[record_evaluation(results)]\n",
    ")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_test = final_model.predict(dtest)\n",
    "\n",
    "# Calculate mean squared error on the test data\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "\n",
    "print(\"Mean squared error on the test data: \", mse_test)\n",
    "\n",
    "# plot the learning curves using the recorded results\n",
    "plt.plot(results[\"Train\"][\"mse\"], label='train')\n",
    "plt.plot(results[\"Test\"][\"mse\"], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hyperparameters from trial 4\n",
    "best_params = {'learning_rate': 0.4033386560764858, \n",
    "               'max_depth': 6, \n",
    "               'n_estimators': 453, \n",
    "               'subsample': 0.8280774098649553, \n",
    "               'colsample_bytree': 0.9340110099277303, \n",
    "               'gamma': 0.8680536696218003,\n",
    "               'objective': 'reg:squarederror'}\n",
    "\n",
    "# Train the model with the best parameters on the entire training data\n",
    "final_model = xgb.XGBRegressor(**best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = final_data_test\n",
    "y_test = test[\"Injury\"].values  # replace \"Injury\" with your target column name\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_test = final_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error on the test data\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "\n",
    "print(\"Mean squared error on the test data: \", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame containing the 'Date' and 'Injury' columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Date'], df['Injury'], marker='o', linestyle=':', color='blue')\n",
    "\n",
    "# Calculating the cutoff date at 80% of the data\n",
    "cutoff_percentage = 0.8\n",
    "cutoff_index = int(len(df) * cutoff_percentage)\n",
    "cutoff_date = df['Date'].iloc[cutoff_index]\n",
    "\n",
    "# Adding the vertical red dotted line at the cutoff date\n",
    "plt.axvline(x=cutoff_date, color='red', linestyle='--')\n",
    "\n",
    "plt.title('Injury Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Injury')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Let's plot the feature importance\n",
    "xgb.plot_importance(final_model)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one-hot encoded feature names\n",
    "ohe_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Get numeric feature names\n",
    "numeric_feature_names = train.drop(cat_cols + ['Date'], axis=1).columns\n",
    "\n",
    "# Combine both lists\n",
    "all_feature_names = np.concatenate([ohe_feature_names, numeric_feature_names])\n",
    "\n",
    "# Now you can find the original feature name for a given index\n",
    "print(all_feature_names[211])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
