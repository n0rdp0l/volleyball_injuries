{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_187679/3391109823.py:3: DtypeWarning: Columns (27,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('df.csv')\n"
     ]
    }
   ],
   "source": [
    "# import df.csv\n",
    "\n",
    "df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Injury</th>\n",
       "      <th>TrainingID_lag_1</th>\n",
       "      <th>TrainingID_lag_2</th>\n",
       "      <th>TrainingID_lag_3</th>\n",
       "      <th>Exercise #_lag_1</th>\n",
       "      <th>Exercise #_lag_2</th>\n",
       "      <th>Exercise #_lag_3</th>\n",
       "      <th>ExerciseID_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Affectedperformance_roll_sum_3</th>\n",
       "      <th>Affectedperformance_roll_sum_7</th>\n",
       "      <th>Symptomscomplaints_roll_sum_3</th>\n",
       "      <th>Symptomscomplaints_roll_sum_7</th>\n",
       "      <th>RPE_roll_sum_3</th>\n",
       "      <th>RPE_roll_sum_7</th>\n",
       "      <th>Duration.player_roll_sum_3</th>\n",
       "      <th>Duration.player_roll_sum_7</th>\n",
       "      <th>Duration.exercise_roll_sum_3</th>\n",
       "      <th>Duration.exercise_roll_sum_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Exercise 6</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>Exercise 6</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245667</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8130.0</td>\n",
       "      <td>32062.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>13548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245668</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11265.0</td>\n",
       "      <td>36195.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>17264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245669</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>34995.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>17264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245670</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22800.0</td>\n",
       "      <td>34995.0</td>\n",
       "      <td>13200.0</td>\n",
       "      <td>17264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245671</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>39330.0</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>19060.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245672 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PlayerID        Date  Injury  TrainingID_lag_1  TrainingID_lag_2  \\\n",
       "0              4  2018-05-11    10.0               NaN               NaN   \n",
       "1              4  2018-05-11    10.0              34.0               NaN   \n",
       "2              4  2018-05-11    10.0              34.0              34.0   \n",
       "3              4  2018-05-11    10.0              34.0              34.0   \n",
       "4              4  2018-05-11    10.0              34.0              34.0   \n",
       "...          ...         ...     ...               ...               ...   \n",
       "245667         4  2018-09-20     NaN               NaN             140.0   \n",
       "245668         4  2018-09-21     7.0               NaN               NaN   \n",
       "245669         4  2018-09-21     7.0             151.0               NaN   \n",
       "245670         4  2018-09-22     NaN             151.0             151.0   \n",
       "245671         4  2018-09-22     NaN             152.0             151.0   \n",
       "\n",
       "        TrainingID_lag_3 Exercise #_lag_1 Exercise #_lag_2 Exercise #_lag_3  \\\n",
       "0                    NaN              NaN              NaN              NaN   \n",
       "1                    NaN       Exercise 3              NaN              NaN   \n",
       "2                    NaN       Exercise 3       Exercise 3              NaN   \n",
       "3                   34.0       Exercise 6       Exercise 3       Exercise 3   \n",
       "4                   34.0       Exercise 3       Exercise 6       Exercise 3   \n",
       "...                  ...              ...              ...              ...   \n",
       "245667             140.0              NaN       Exercise 2       Exercise 3   \n",
       "245668             140.0              NaN              NaN       Exercise 2   \n",
       "245669               NaN       Exercise 2              NaN              NaN   \n",
       "245670               NaN       Exercise 1       Exercise 2              NaN   \n",
       "245671             151.0       Exercise 2       Exercise 1       Exercise 2   \n",
       "\n",
       "        ExerciseID_lag_1  ...  Affectedperformance_roll_sum_3  \\\n",
       "0                    NaN  ...                             NaN   \n",
       "1                   11.0  ...                             NaN   \n",
       "2                   11.0  ...                             NaN   \n",
       "3                    8.0  ...                             0.0   \n",
       "4                   11.0  ...                             0.0   \n",
       "...                  ...  ...                             ...   \n",
       "245667               NaN  ...                             2.0   \n",
       "245668               NaN  ...                             2.0   \n",
       "245669             133.0  ...                             2.0   \n",
       "245670              82.0  ...                             2.0   \n",
       "245671              83.0  ...                             2.0   \n",
       "\n",
       "        Affectedperformance_roll_sum_7 Symptomscomplaints_roll_sum_3  \\\n",
       "0                                  NaN                           NaN   \n",
       "1                                  NaN                           NaN   \n",
       "2                                  NaN                           NaN   \n",
       "3                                  NaN                           0.0   \n",
       "4                                  NaN                           0.0   \n",
       "...                                ...                           ...   \n",
       "245667                             6.0                           2.0   \n",
       "245668                             6.0                           2.0   \n",
       "245669                             6.0                           2.0   \n",
       "245670                             5.0                           2.0   \n",
       "245671                             4.0                           2.0   \n",
       "\n",
       "       Symptomscomplaints_roll_sum_7 RPE_roll_sum_3 RPE_roll_sum_7  \\\n",
       "0                                NaN            NaN            NaN   \n",
       "1                                NaN            NaN            NaN   \n",
       "2                                NaN            NaN            NaN   \n",
       "3                                NaN           12.0            NaN   \n",
       "4                                NaN           12.0            NaN   \n",
       "...                              ...            ...            ...   \n",
       "245667                           6.0           14.0           39.0   \n",
       "245668                           6.0            7.0           35.0   \n",
       "245669                           6.0            0.0           28.0   \n",
       "245670                           5.0            0.0           21.0   \n",
       "245671                           4.0            0.0           14.0   \n",
       "\n",
       "       Duration.player_roll_sum_3 Duration.player_roll_sum_7  \\\n",
       "0                             NaN                        NaN   \n",
       "1                             NaN                        NaN   \n",
       "2                             NaN                        NaN   \n",
       "3                         17892.0                        NaN   \n",
       "4                         17892.0                        NaN   \n",
       "...                           ...                        ...   \n",
       "245667                     8130.0                    32062.0   \n",
       "245668                    11265.0                    36195.0   \n",
       "245669                    14400.0                    34995.0   \n",
       "245670                    22800.0                    34995.0   \n",
       "245671                    31200.0                    39330.0   \n",
       "\n",
       "        Duration.exercise_roll_sum_3  Duration.exercise_roll_sum_7  \n",
       "0                                NaN                           NaN  \n",
       "1                                NaN                           NaN  \n",
       "2                                NaN                           NaN  \n",
       "3                             1163.0                           NaN  \n",
       "4                             1920.0                           NaN  \n",
       "...                              ...                           ...  \n",
       "245667                        3460.0                       13548.0  \n",
       "245668                        5400.0                       17264.0  \n",
       "245669                        7200.0                       17264.0  \n",
       "245670                       13200.0                       17264.0  \n",
       "245671                       15600.0                       19060.0  \n",
       "\n",
       "[245672 rows x 133 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your dataframe is df and your date column is 'date'\n",
    "\n",
    "# Convert date to datetime if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort by date\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Remove rows where the 'Injury' column has NA values\n",
    "df = df.dropna(subset=['Injury'])\n",
    "\n",
    "# Get unique dates\n",
    "unique_dates = df['Date'].unique()\n",
    "\n",
    "# Decide how many dates to include in each set\n",
    "train_dates = int(len(unique_dates) * 0.8)\n",
    "\n",
    "# Find the index of the last training date\n",
    "last_train_idx = df[df['Date'] == unique_dates[train_dates]].index[-1]\n",
    "\n",
    "# Now you can create your train and test sets\n",
    "train = df.iloc[:last_train_idx + 1]\n",
    "test = df.iloc[last_train_idx + 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Injury</th>\n",
       "      <th>TrainingID_lag_1</th>\n",
       "      <th>TrainingID_lag_2</th>\n",
       "      <th>TrainingID_lag_3</th>\n",
       "      <th>Exercise #_lag_1</th>\n",
       "      <th>Exercise #_lag_2</th>\n",
       "      <th>Exercise #_lag_3</th>\n",
       "      <th>ExerciseID_lag_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Affectedperformance_roll_sum_3</th>\n",
       "      <th>Affectedperformance_roll_sum_7</th>\n",
       "      <th>Symptomscomplaints_roll_sum_3</th>\n",
       "      <th>Symptomscomplaints_roll_sum_7</th>\n",
       "      <th>RPE_roll_sum_3</th>\n",
       "      <th>RPE_roll_sum_7</th>\n",
       "      <th>Duration.player_roll_sum_3</th>\n",
       "      <th>Duration.player_roll_sum_7</th>\n",
       "      <th>Duration.exercise_roll_sum_3</th>\n",
       "      <th>Duration.exercise_roll_sum_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243949</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28636.0</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>4568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243948</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28636.0</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>4568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243947</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28636.0</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>4568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243796</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28636.0</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>3152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243795</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>Exercise 4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28636.0</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>3152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245663</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23932.0</td>\n",
       "      <td>36200.0</td>\n",
       "      <td>10088.0</td>\n",
       "      <td>11975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245664</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24930.0</td>\n",
       "      <td>37198.0</td>\n",
       "      <td>11864.0</td>\n",
       "      <td>14500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245665</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>7.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Exercise 3</td>\n",
       "      <td>Exercise 1</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>20595.0</td>\n",
       "      <td>38196.0</td>\n",
       "      <td>10064.0</td>\n",
       "      <td>14808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245668</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11265.0</td>\n",
       "      <td>36195.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>17264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245669</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exercise 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>34995.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>17264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21731 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PlayerID       Date  Injury  TrainingID_lag_1  TrainingID_lag_2  \\\n",
       "243949         4 2018-09-05     9.0             122.0             122.0   \n",
       "243948         4 2018-09-05     9.0             122.0             122.0   \n",
       "243947         4 2018-09-05     9.0             122.0             122.0   \n",
       "243796         4 2018-09-05     9.0             122.0             122.0   \n",
       "243795         4 2018-09-05     9.0             122.0             122.0   \n",
       "...          ...        ...     ...               ...               ...   \n",
       "245663         4 2018-09-18     7.0             150.0             150.0   \n",
       "245664         4 2018-09-18     7.0             140.0             150.0   \n",
       "245665         4 2018-09-18     7.0             140.0             140.0   \n",
       "245668         4 2018-09-21     7.0               NaN               NaN   \n",
       "245669         4 2018-09-21     7.0             151.0               NaN   \n",
       "\n",
       "        TrainingID_lag_3 Exercise #_lag_1 Exercise #_lag_2 Exercise #_lag_3  \\\n",
       "243949             122.0       Exercise 1       Exercise 1       Exercise 1   \n",
       "243948             122.0       Exercise 1       Exercise 1       Exercise 1   \n",
       "243947             122.0       Exercise 1       Exercise 1       Exercise 1   \n",
       "243796             122.0       Exercise 4       Exercise 4       Exercise 4   \n",
       "243795             122.0       Exercise 4       Exercise 4       Exercise 4   \n",
       "...                  ...              ...              ...              ...   \n",
       "245663             139.0       Exercise 2       Exercise 1       Exercise 3   \n",
       "245664             150.0       Exercise 1       Exercise 2       Exercise 1   \n",
       "245665             150.0       Exercise 3       Exercise 1       Exercise 2   \n",
       "245668             140.0              NaN              NaN       Exercise 2   \n",
       "245669               NaN       Exercise 2              NaN              NaN   \n",
       "\n",
       "        ExerciseID_lag_1  ...  Affectedperformance_roll_sum_3  \\\n",
       "243949              63.0  ...                             0.0   \n",
       "243948              63.0  ...                             0.0   \n",
       "243947              63.0  ...                             0.0   \n",
       "243796              13.0  ...                             0.0   \n",
       "243795              13.0  ...                             0.0   \n",
       "...                  ...  ...                             ...   \n",
       "245663             132.0  ...                             4.0   \n",
       "245664              47.0  ...                             4.0   \n",
       "245665              88.0  ...                             4.0   \n",
       "245668               NaN  ...                             2.0   \n",
       "245669             133.0  ...                             2.0   \n",
       "\n",
       "        Affectedperformance_roll_sum_7 Symptomscomplaints_roll_sum_3  \\\n",
       "243949                             0.0                           0.0   \n",
       "243948                             0.0                           0.0   \n",
       "243947                             0.0                           0.0   \n",
       "243796                             0.0                           0.0   \n",
       "243795                             0.0                           0.0   \n",
       "...                                ...                           ...   \n",
       "245663                             8.0                           4.0   \n",
       "245664                             8.0                           4.0   \n",
       "245665                             8.0                           4.0   \n",
       "245668                             6.0                           2.0   \n",
       "245669                             6.0                           2.0   \n",
       "\n",
       "       Symptomscomplaints_roll_sum_7 RPE_roll_sum_3 RPE_roll_sum_7  \\\n",
       "243949                           0.0           28.0           56.0   \n",
       "243948                           0.0           28.0           56.0   \n",
       "243947                           0.0           28.0           56.0   \n",
       "243796                           0.0           28.0           56.0   \n",
       "243795                           0.0           28.0           56.0   \n",
       "...                              ...            ...            ...   \n",
       "245663                           8.0           25.0           41.0   \n",
       "245664                           8.0           28.0           44.0   \n",
       "245665                           8.0           28.0           47.0   \n",
       "245668                           6.0            7.0           35.0   \n",
       "245669                           6.0            0.0           28.0   \n",
       "\n",
       "       Duration.player_roll_sum_3 Duration.player_roll_sum_7  \\\n",
       "243949                    28636.0                    57272.0   \n",
       "243948                    28636.0                    57272.0   \n",
       "243947                    28636.0                    57272.0   \n",
       "243796                    28636.0                    57272.0   \n",
       "243795                    28636.0                    57272.0   \n",
       "...                           ...                        ...   \n",
       "245663                    23932.0                    36200.0   \n",
       "245664                    24930.0                    37198.0   \n",
       "245665                    20595.0                    38196.0   \n",
       "245668                    11265.0                    36195.0   \n",
       "245669                    14400.0                    34995.0   \n",
       "\n",
       "        Duration.exercise_roll_sum_3  Duration.exercise_roll_sum_7  \n",
       "243949                        2284.0                        4568.0  \n",
       "243948                        2284.0                        4568.0  \n",
       "243947                        2284.0                        4568.0  \n",
       "243796                        1576.0                        3152.0  \n",
       "243795                        1576.0                        3152.0  \n",
       "...                              ...                           ...  \n",
       "245663                       10088.0                       11975.0  \n",
       "245664                       11864.0                       14500.0  \n",
       "245665                       10064.0                       14808.0  \n",
       "245668                        5400.0                       17264.0  \n",
       "245669                        7200.0                       17264.0  \n",
       "\n",
       "[21731 rows x 133 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "[I 2023-06-22 12:48:13,813] A new study created in memory with name: no-name-9f9a3fa3-a747-4c32-b412-eaca0e7bb287\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[I 2023-06-22 12:50:19,726] Trial 0 finished with value: 0.11738664704165595 and parameters: {'learning_rate': 0.014273667816830522, 'max_depth': 10, 'n_estimators': 239, 'subsample': 0.8369862751496528, 'colsample_bytree': 0.6476564847939109, 'gamma': 0.31594346276254304}. Best is trial 0 with value: 0.11738664704165595.\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[I 2023-06-22 12:54:21,723] Trial 1 finished with value: 0.3993278287193231 and parameters: {'learning_rate': 0.35003335586166334, 'max_depth': 8, 'n_estimators': 185, 'subsample': 0.7308183007594956, 'colsample_bytree': 0.5746679191894803, 'gamma': 0.12148399890903616}. Best is trial 0 with value: 0.11738664704165595.\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[I 2023-06-22 12:57:27,317] Trial 2 finished with value: 0.1537595851955718 and parameters: {'learning_rate': 0.16894669546855112, 'max_depth': 7, 'n_estimators': 189, 'subsample': 0.6580605552380113, 'colsample_bytree': 0.5866455973104575, 'gamma': 0.7940952184290604}. Best is trial 0 with value: 0.11738664704165595.\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[I 2023-06-22 13:01:56,614] Trial 3 finished with value: 0.5793952446921457 and parameters: {'learning_rate': 0.32841646144166664, 'max_depth': 9, 'n_estimators': 291, 'subsample': 0.9084740648594178, 'colsample_bytree': 0.5592620608306069, 'gamma': 0.17223269475470548}. Best is trial 0 with value: 0.11738664704165595.\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[I 2023-06-22 13:07:49,191] Trial 4 finished with value: 0.000933865326577385 and parameters: {'learning_rate': 0.4033386560764858, 'max_depth': 6, 'n_estimators': 453, 'subsample': 0.8280774098649553, 'colsample_bytree': 0.9340110099277303, 'gamma': 0.8680536696218003}. Best is trial 4 with value: 0.000933865326577385.\n",
      "/tmp/ipykernel_187679/2207171335.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:32: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:33: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
      "/tmp/ipykernel_187679/2207171335.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
      "[W 2023-06-22 13:14:19,296] Trial 5 failed with parameters: {'learning_rate': 0.5044405253739318, 'max_depth': 7, 'n_estimators': 477, 'subsample': 0.5139159078038427, 'colsample_bytree': 0.8663480587817952, 'gamma': 0.7211552458450965} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_187679/2207171335.py\", line 45, in objective\n",
      "    model.fit(X_train_cv, y_train_cv)\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/n0rdp0l/anaconda3/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-22 13:14:19,308] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(mse_scores)\n\u001b[1;32m     53\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[1;32m     56\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m     58\u001b[0m final_model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     42\u001b[0m y_train_cv, y_val_cv \u001b[39m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m     44\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 45\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_cv, y_train_cv)\n\u001b[1;32m     47\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val_cv)\n\u001b[1;32m     48\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_val_cv, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m (\n\u001b[1;32m   1017\u001b[0m     model,\n\u001b[1;32m   1018\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1024\u001b[0m )\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1026\u001b[0m     params,\n\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Identify categorical columns excluding the date column\n",
    "cat_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "# Fit the OneHotEncoder on the training data and transform both train and test data\n",
    "ohe.fit(train[cat_cols])\n",
    "one_hot_encoded_train = ohe.transform(train[cat_cols])\n",
    "one_hot_encoded_test = ohe.transform(test[cat_cols])\n",
    "\n",
    "# Extract numeric data\n",
    "numeric_data_train = train.drop(cat_cols + ['Date'], axis=1).values\n",
    "numeric_data_test = test.drop(cat_cols + ['Date'], axis=1).values\n",
    "\n",
    "# Combine sparse and dense data\n",
    "final_data_train = sp.hstack((one_hot_encoded_train, numeric_data_train)).tocsr()\n",
    "final_data_test = sp.hstack((one_hot_encoded_test, numeric_data_test)).tocsr()\n",
    "\n",
    "# Set up for cross-validation\n",
    "X = final_data_train\n",
    "y = train[\"Injury\"].values  # replace \"Injury\" with your target column name\n",
    "\n",
    "# Initialize a TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0.0, 1.0),\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "\n",
    "    mse_scores = []\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train_cv, X_val_cv = X[train_index], X[val_index]\n",
    "        y_train_cv, y_val_cv = y[train_index], y[val_index]\n",
    "\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        y_pred = model.predict(X_val_cv)\n",
    "        mse = mean_squared_error(y_val_cv, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params_\n",
    "\n",
    "final_model = xgb.XGBRegressor(objective='reg:squarederror', **best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "predictions = final_model.predict(final_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on the test data:  6.29169313312704e-06\n"
     ]
    }
   ],
   "source": [
    "# Extract hyperparameters from trial 4\n",
    "best_params = {'learning_rate': 0.4033386560764858, \n",
    "               'max_depth': 6, \n",
    "               'n_estimators': 453, \n",
    "               'subsample': 0.8280774098649553, \n",
    "               'colsample_bytree': 0.9340110099277303, \n",
    "               'gamma': 0.8680536696218003,\n",
    "               'objective': 'reg:squarederror'}\n",
    "\n",
    "# Train the model with the best parameters on the entire training data\n",
    "final_model = xgb.XGBRegressor(**best_params)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = final_data_test\n",
    "y_test = test[\"Injury\"].values  # replace \"Injury\" with your target column name\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_test = final_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error on the test data\n",
    "mse_test = mean_squared_error(y_test, predictions_test)\n",
    "\n",
    "print(\"Mean squared error on the test data: \", mse_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
